{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/rajivsam/interactive_tutorials/blob/master/notebooks/Graph_Embeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PCDeBByKW2nj"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!git clone -b oasis_connector --single-branch https://github.com/arangodb/interactive_tutorials.git\n",
    "!git clone -b imdb_with_ratings https://github.com/arangodb/interactive_tutorials imdb_data\n",
    "!rsync -av interactive_tutorials/ ./ --exclude=.git\n",
    "!chmod -R 755 ./tools\n",
    "!pip3 install pyarango\n",
    "!pip3 install \"python-arango>=5.0\"\n",
    "!pip3 install networkx\n",
    "!pip3 install matplotlib\n",
    "!pip3 install adbnx-adapter\n",
    "!pip install node2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cO6lyKJo5o6U"
   },
   "source": [
    "Scope:\n",
    "1. What are Graph Embeddings\n",
    "2. Motivate the ideas used to develop a graph embedding\n",
    "3. What are the approaches to developing a graph embedding.\n",
    "4. What are the characteristics of each approach. \n",
    "5. What are the strengths and limitations of each approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BuPPHyUIXdxD"
   },
   "source": [
    "## Graph Embeddings\n",
    "Mathematically, a graph is a structure that captures a set of objects and the relations between them. This representation has had a remarkable versatility in the abstraction of a wide variety of scientific and business problems. Road, networks, water pipeline networks, traffic networks, oil/chemical networks, supply-chains, computer networks, recommender systems in electronic market places are all examples of graphs. Since graph structured data are pervasive, problems on graphs have been researched for a long time now. These solutions are exploited to provide very useful applications in many domains. Finding best delivery routes, identifying influential writers in content networks, detecting fraud in financial transactions are all examples. Many of these features are available as part of the ArangoDB analytics eco-system. With the current explosion of interest machine learning, there is a surge in interest in developing machine learning applications on graphs. In this post we will discuss one approach to performing machine learning on graphs. The material for this post comes from [this paper](https://www-cs.stanford.edu/people/jure/pubs/graphrepresentation-ieee17.pdf) and [these slides/notes](http://snap.stanford.edu/proj/embeddings-www/files/nrltutorial-part2-gnns.pdf).\n",
    "The key idea is to convert the data which has a representation as a graph to a representation commonly used machine learning. This representation is called the Euclidean representation. The crucial idea with this representation is that the notion of distance between two nodes exist. Nodes in the graph are transformed into points in a Euclidean representation. \n",
    "A basic template to learn this Euclidean representation is:\n",
    "1. Define the set of nodes which we deem to be similar. This is the notion of neighborhood of the node.\n",
    "2. Posit that nodes that are similar in the graph are similar in the Euclidean representation. In otherwords, the similarity in the set of nodes (ie., neighborhood) is preserved as go from the graph to Euclidean representation.\n",
    "3. Develop a neural network in which the set of nodes that are similar in the graph are provided as the input to the network and Euclidean representation is what is learned. The neural network represents an _encoder_ that uses a _similarity_ measure to determine a Euclidean representation. The parameters of the network are learned so that similarity in the graph representation is preserved in the Euclidean representation.\n",
    "\n",
    "As discussed in [the slides/notes](http://snap.stanford.edu/proj/embeddings-www/files/nrltutorial-part2-gnns.pdf), we can consider the following as the set of nodes for which similarity in the graph is evaluated:\n",
    "1. Nodes that are adjacent to a node\n",
    "2. Nodes that are reachable by $k$ hops from the node.\n",
    "3. Nodes that manifest in a random walk of a specified length starting at the node.\n",
    "\n",
    "    Each of these strategies have strengths and weakness and are particularly suited to certain applications as discussed in [goyal and ferrera, 2017](https://usc-isi-i2.github.io/papers/goyal18-knosys.pdf). The third approach is what we will discuss in this post. This approach of capturing the neighborhood of the node is called a _random-walk_. The Euclidean representation of the nodes obtained from the neural network are called _embeddings_. To obtain these embeddings, random walks of particular lengths are initiated from each node of the graph. The nodes visited by the walk are captured sequentially until a walk of the desired length is completed. The generated walks are fed as input to the neural network and the parameters of the neural network are learned as part of training the network. As a result of training, we obtain the Euclidean representation of the nodes of the graph. These node representations can be used to peform machine learning tasks such as _node_ _classification_ and _link_ _prediction_. A schematic illustrating the basic elements of an approach to obtaining embeddings from a graph is shown below. This illustration depicts using a _random walk_ of length 4 from each node of the graph. A sample of _random walks_ from node A and node B are shown. These _random walks_ are then used as input to a neural network. The embeddings are obtained as an output of the neural network. To determine the parameters (the weights and biases) of the neural network, we utilize the fact that nodes that are similar in the graph, such as those encountered in a _random walk_ are similar in the embeddeding. The output from the neural network is a vector. This is a mathematical object with co-ordinates or dimensions. The number of dimensions the embedding has is a parameter (actually, a _hyper parameter_, since this is not learned by the neural network) that we need to specify when the neural network is developed. Machine learning methods, for example, the [_t Stochastic Neighborhood Embedding(tSNE)_](https://distill.pub/2016/misread-tsne/), can be used to visualize a two-dimensional version of the embedding. Instead of using a neural network, it is also possible to use methods such as _graph factorization_ to obtain embeddings from the graph. ![](./img/embedding_schematic.png)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-kxg1FtPLgrJ"
   },
   "source": [
    "The approach using just an _encoder_ function and a _similarity_ metric is an example of a _shallow_ approach to learning an embedding. Some of the drawbacks of using this approach are:\n",
    "1. Learning an embedding requires determining a large number of parameters - in the order of the number of nodes in a graph ($\\mathbf{O}(\\left|V\\right|)$, where $V$ represents the number of nodes in the graph).\n",
    "2. The learning is _transductive_. The embeddings that can be determined are limited to the nodes seen during training. We will not be able to determine an embedding for nodes that were not seen as part of the training process.\n",
    "3. Inability to incorporate node features in determining the embedding. \n",
    "\n",
    "Instead of just using a simple _encoder_ and _similarity_ measure to determine a Euclidean representation, it is possible to use more sophisticated approach to determining a representation for the graph. In contrast, we can use a _deeper_ approach using _Graph Neural Networks (GNN)_. In a _GNN_ nodes aggregate information from their neighbors using a _neural network_ . This approach eliminates some of the draw backs observed with the shallow approach. A schematic of the computational approach for _GNN's_ is shown below. ![](./img/gnn_schematic.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "import oasis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = pprint.PrettyPrinter()\n",
    "\n",
    "## Retrieve tmp credentials from ArangoDB Tutorial Service\n",
    "login = oasis.getTempCredentials(credentialProvider='https://db66745e680e.arangodb.cloud:8529/_db/_system/tutorialDB/tutorialDB')\n",
    "\n",
    "## Connect to the temp database\n",
    "test_db = oasis.connect_python_arango(login)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp.pprint(login)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not test_db.has_graph(\"imdb_graph\"):\n",
    "    test_db.create_graph('imdb_graph', smart=True)\n",
    "\n",
    "if not test_db.has_graph(\"user_user_graph\"):\n",
    "    test_db.create_graph(\"user_user_graph\", smart=True)\n",
    "    \n",
    "imdb_graph = test_db.graph(\"imdb_graph\")\n",
    "user_user_graph = test_db.graph(\"user_user_graph\")\n",
    "if not imdb_graph.has_vertex_collection(\"Users\"):\n",
    "    imdb_graph.create_vertex_collection(\"Users\")\n",
    "if not imdb_graph.has_vertex_collection(\"Movies\"):\n",
    "    imdb_graph.create_vertex_collection(\"Movies\")\n",
    "if not test_db.has_collection(\"Ratings\"):\n",
    "    test_db.create_collection(\"Ratings\", edge=True)\n",
    "if not imdb_graph.has_edge_definition(\"Ratings\"):\n",
    "    ratings = imdb_graph.create_edge_definition(\n",
    "        edge_collection='Ratings',\n",
    "        from_vertex_collections=['Users'],\n",
    "        to_vertex_collections=['Movies']\n",
    "    )\n",
    "if not test_db.has_collection(\"User_User_Sim\"):\n",
    "    test_db.create_collection(\"User_User_Sim\", edge=True)\n",
    "    \n",
    "if not user_user_graph.has_edge_definition(\"User_User_Sim\"):\n",
    "    user_user_sim = user_user_graph.create_edge_definition(\n",
    "        edge_collection='User_User_Sim',\n",
    "        from_vertex_collections=['Users'],\n",
    "        to_vertex_collections=['Users']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ./tools/arangorestore -c none --create-collection true --server.endpoint http+ssl://{login[\"hostname\"]}:{login[\"port\"]} --server.username {login[\"username\"]} --server.database {login[\"dbName\"]} --server.password {login[\"password\"]} --default-replication-factor 3  --input-directory \"./imdb_data/data/imdb_with_ratings\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = {\"username\": login[\"username\"], \"password\": login[\"password\"],\\\n",
    "       \"dbName\": login[\"dbName\"], \"hostname\": login[\"hostname\"],\\\n",
    "       \"port\": login[\"port\"], \"protocol\": \"https\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_attributes = {'vertexCollections': {'Users': {},\n",
    "                                         'Movies': {}},\n",
    "                   'edgeCollections': {'Ratings': {'_from', '_to', 'ratings'}}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from adbnx_adapter.imdb_arangoDB_networkx_adapter import IMDBArangoDB_Networkx_Adapter\n",
    "ma = IMDBArangoDB_Networkx_Adapter(conn=con)\n",
    "g = ma.create_networkx_graph(\n",
    "    graph_name='IMDBGraph',  graph_attributes=imdb_attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_nodes = [n for n in g.nodes() if n.startswith(\"Users\")]\n",
    "movie_nodes = [n for n in g.nodes() if n.startswith(\"Movies\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of Users are %d\" % (len(user_nodes)))\n",
    "print(\"Number of Movies are %d\" % (len(movie_nodes)))\n",
    "print(\"Number of Ratings are %d\" % (len(list(g.edges()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "B = nx.Graph()\n",
    "B.add_nodes_from(user_nodes, bipartite=0)\n",
    "B.add_nodes_from(movie_nodes, bipartite=1)\n",
    "B.add_edges_from(list(g.edges()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from networkx.algorithms import bipartite\n",
    "cr = bipartite.clustering(B)\n",
    "cu = {}\n",
    "cm = {}\n",
    "for k, v in sorted(cr.items(),reverse=True, key=lambda item: item[1]):\n",
    "    if k.startswith(\"Users\"):\n",
    "        cu[k] = v\n",
    "    else:\n",
    "        cm[k] = v\n",
    "\n",
    "del cr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t10cu = list(cu.keys())[:10]\n",
    "proj_user = nx.bipartite.projected_graph(B, t10cu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "%time\n",
    "num_embs = proj_user.number_of_nodes()\n",
    "index = 0\n",
    "\n",
    "batch = []\n",
    "BATCH_SIZE = 500\n",
    "batch_idx = 1\n",
    "collection =test_db[\"User_User_Sim\"]\n",
    "el = proj_user.edges()\n",
    "for e in el:\n",
    "    insert_doc1 = {\"_from\": e[0], \"_to\": e[1]}\n",
    "    insert_doc2 = {\"_from\": e[1], \"_to\": e[0]}\n",
    "    batch.append(insert_doc1)\n",
    "    batch.append(insert_doc2)\n",
    "    index += 2\n",
    "    last_record = (index == (len(el) - 2)) \n",
    "    if index % BATCH_SIZE == 0:\n",
    "        print(\"Inserting batch %d\" % (batch_idx))\n",
    "        batch_idx += 1\n",
    "        collection.import_bulk(batch)\n",
    "        batch = []\n",
    "    if last_record and len(batch) > 0:\n",
    "        print(\"Inserting batch the last batch!\")\n",
    "        collection.import_bulk(batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from node2vec import Node2Vec\n",
    "node2vec = Node2Vec(proj_user, dimensions=64, walk_length=10, num_walks=10, workers=4)\n",
    "model = node2vec.fit(window=10, min_count=1, batch_words=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t10cu_emb = { n: list(map(float,model.wv.get_vector(n))) for n in proj_user.nodes()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "%time\n",
    "num_embs = proj_user.number_of_nodes()\n",
    "index = 0\n",
    "collection =test_db[\"Users\"]\n",
    "batch = []\n",
    "BATCH_SIZE = 500\n",
    "batch_idx = 1\n",
    "for u, e in t10cu_emb.items():\n",
    "    update_doc = {}\n",
    "    the_key = u.split('/')[1]\n",
    "    update_doc['_id'] = u\n",
    "    update_doc['n2v_emb'] = e\n",
    "    batch.append(update_doc)\n",
    "    index += 1\n",
    "    last_record = (index == (num_embs - 1)) \n",
    "    if index % BATCH_SIZE == 0:\n",
    "        print(\"Inserting batch %d\" % (batch_idx))\n",
    "        batch_idx += 1\n",
    "        collection.update_many(batch)\n",
    "        batch = []\n",
    "    if last_record and len(batch) > 0:\n",
    "        print(\"Inserting batch the last batch!\")\n",
    "        collection.update_many(batch)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Graph_Embeddings.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
