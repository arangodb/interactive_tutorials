{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dy5TgYTJfKcX"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/arangodb/interactive_tutorials/blob/master/notebooks/Graph_Embeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PCDeBByKW2nj"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!git clone -b oasis_connector --single-branch https://github.com/arangodb/interactive_tutorials.git\n",
    "!git clone -b imdb_with_ratings https://github.com/arangodb/interactive_tutorials imdb_data\n",
    "!rsync -av interactive_tutorials/ ./ --exclude=.git\n",
    "!chmod -R 755 ./tools\n",
    "!pip3 install pyarango\n",
    "!pip3 install \"python-arango>=5.0\"\n",
    "!pip3 install networkx\n",
    "!pip3 install matplotlib\n",
    "!pip3 install adbnx-adapter==0.0.0.2.5.3.post1\n",
    "!pip install node2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cO6lyKJo5o6U"
   },
   "source": [
    "Scope:\n",
    "1. What are Graph Embeddings\n",
    "2. Motivate the ideas used to develop a graph embedding\n",
    "3. What are the approaches to developing a graph embedding.\n",
    "4. What are the characteristics of each approach. \n",
    "5. What are the strengths and limitations of each approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BuPPHyUIXdxD"
   },
   "source": [
    "## Graph Embeddings\n",
    "Mathematically, a graph is a structure that captures a set of objects and the relations between them. This representation has had a remarkable versatility in the abstraction of a wide variety of scientific and business problems. Road, networks, water pipeline networks, traffic networks, oil/chemical networks, supply-chains, computer networks, recommender systems in electronic market places are all examples of graphs. Since graph structured data are pervasive, problems on graphs have been researched for a long time now. These solutions are exploited to provide very useful applications in many domains. Finding best delivery routes, identifying influential writers in content networks, detecting fraud in financial transactions are all examples. Many of these features are available as part of the ArangoDB analytics eco-system. With the current explosion of interest machine learning, there is a surge in interest in developing machine learning applications on graphs. In this post we will discuss one approach to performing machine learning on graphs. The material for this post comes from [this paper](https://www-cs.stanford.edu/people/jure/pubs/graphrepresentation-ieee17.pdf) and [these slides/notes](http://snap.stanford.edu/proj/embeddings-www/files/nrltutorial-part2-gnns.pdf).\n",
    "The key idea is to convert the data which has a representation as a graph to a representation commonly used machine learning. This representation is called the Euclidean representation. The crucial idea with this representation is that the notion of distance between two nodes exist. Nodes in the graph are transformed into points in a Euclidean representation. \n",
    "A basic template to learn this Euclidean representation is:\n",
    "1. Define the set of nodes which we deem to be similar. This is the notion of neighborhood of the node.\n",
    "2. Posit that nodes that are similar in the graph are similar in the Euclidean representation. In otherwords, the similarity in the set of nodes (ie., neighborhood) is preserved as go from the graph to Euclidean representation.\n",
    "3. Develop a neural network in which the set of nodes that are similar in the graph are provided as the input to the network and Euclidean representation is what is learned. The neural network represents an _encoder_ that uses a _similarity_ measure to determine a Euclidean representation. The parameters of the network are learned so that similarity in the graph representation is preserved in the Euclidean representation.\n",
    "\n",
    "As discussed in [the slides/notes](http://snap.stanford.edu/proj/embeddings-www/files/nrltutorial-part2-gnns.pdf), we can consider the following as the set of nodes for which similarity in the graph is evaluated:\n",
    "1. Nodes that are adjacent to a node\n",
    "2. Nodes that are reachable by $k$ hops from the node.\n",
    "3. Nodes that manifest in a random walk of a specified length starting at the node.\n",
    "\n",
    "    Each of these strategies have strengths and weakness and are particularly suited to certain applications as discussed in [goyal and ferrera, 2017](https://usc-isi-i2.github.io/papers/goyal18-knosys.pdf). The third approach is what we will discuss in this post. This approach of capturing the neighborhood of the node is called a _random-walk_. The Euclidean representation of the nodes obtained from the neural network are called _embeddings_. To obtain these embeddings, random walks of particular lengths are initiated from each node of the graph. The nodes visited by the walk are captured sequentially until a walk of the desired length is completed. The generated walks are fed as input to the neural network and the parameters of the neural network are learned as part of training the network. As a result of training, we obtain the Euclidean representation of the nodes of the graph. These node representations can be used to peform machine learning tasks such as _node_ _classification_ and _link_ _prediction_. A schematic illustrating the basic elements of an approach to obtaining embeddings from a graph is shown below. This illustration depicts using a _random walk_ of length 4 from each node of the graph. A sample of _random walks_ from node A and node B are shown. These _random walks_ are then used as input to a neural network. The embeddings are obtained as an output of the neural network. To determine the parameters (the weights and biases) of the neural network, we utilize the fact that nodes that are similar in the graph, such as those encountered in a _random walk_ are similar in the embeddeding. The output from the neural network is a vector. This is a mathematical object with co-ordinates or dimensions. The number of dimensions the embedding has is a parameter (actually, a _hyper parameter_, since this is not learned by the neural network) that we need to specify when the neural network is developed. Machine learning methods, for example, the [_t Stochastic Neighborhood Embedding(tSNE)_](https://distill.pub/2016/misread-tsne/), can be used to visualize a two-dimensional version of the embedding. Instead of using a neural network, it is also possible to use methods such as _graph factorization_ to obtain embeddings from the graph. ![](https://github.com/arangodb/interactive_tutorials/blob/master/notebooks/img/embedding_schematic.png?raw=1)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-kxg1FtPLgrJ"
   },
   "source": [
    "The approach using just an _encoder_ function and a _similarity_ metric is an example of a _shallow_ approach to learning an embedding. Some of the drawbacks of using this approach are:\n",
    "1. Learning an embedding requires determining a large number of parameters - in the order of the number of nodes in a graph ($\\mathbf{O}(\\left|V\\right|)$, where $V$ represents the number of nodes in the graph).\n",
    "2. The learning is _transductive_. The embeddings that can be determined are limited to the nodes seen during training. We will not be able to determine an embedding for nodes that were not seen as part of the training process.\n",
    "3. Inability to incorporate node features in determining the embedding. \n",
    "\n",
    "Instead of just using a simple _encoder_ and _similarity_ measure to determine a Euclidean representation, it is possible to use more sophisticated approach to determining a representation for the graph. In contrast, we can use a _deeper_ approach using _Graph Neural Networks (GNN)_. In a _GNN_ nodes aggregate information from their neighbors using a _neural network_ . This approach eliminates some of the draw backs observed with the shallow approach. A schematic of the computational approach for _GNN's_ is shown below. ![](https://github.com/arangodb/interactive_tutorials/blob/master/notebooks/img/gnn_schematic.png?raw=1)\n",
    "\n",
    "\n",
    "This notebook illustrates the shallow approach to embedding using _Node2vec_. An illustration of the deeper approach will follow shortly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q-uk0VnZfKcd"
   },
   "outputs": [],
   "source": [
    "import pprint\n",
    "import oasis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = pprint.PrettyPrinter()\n",
    "\n",
    "## Retrieve tmp credentials from ArangoDB Tutorial Service\n",
    "login = oasis.getTempCredentials(credentialProvider='https://tutorials.arangodb.cloud:8529/_db/_system/tutorialDB/tutorialDB', tutorialName=\"GraphEmbeddings\")\n",
    "\n",
    "## Connect to the temp database\n",
    "test_db = oasis.connect_python_arango(login)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp.pprint(login)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below cell introduces you with a basics of how do we create graphs in ArangoDB. A graph consists of vertices and edges. Vertices are stored as documents in vertex collections and edges stored as documents in edge collections. The collections used in a graph and their relations are specified with edge definitions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GkSUWOqUfKcd"
   },
   "outputs": [],
   "source": [
    "# create a new graph called imdb_graph in the temp database if it does not already exist.\n",
    "if not test_db.has_graph(\"imdb_graph\"):\n",
    "    test_db.create_graph('imdb_graph', smart=True)\n",
    "\n",
    "# create a new graph called user_user_graph in the temp database if it does not already exist.\n",
    "if not test_db.has_graph(\"user_user_graph\"):\n",
    "    test_db.create_graph(\"user_user_graph\", smart=True)\n",
    "\n",
    "# This returns and API wrapper for the above created graphs\n",
    "imdb_graph = test_db.graph(\"imdb_graph\")\n",
    "user_user_graph = test_db.graph(\"user_user_graph\")\n",
    "\n",
    "# create a new collection named \"Users\" if it does not exist.\n",
    "# This returns an API wrapper for \"Users\" collection.\n",
    "if not test_db.has_collection(\"Users\"):\n",
    "    test_db.create_collection(\"Users\", replication_factor=3)\n",
    "\n",
    "# Create a new vertex collection named \"Users\" if it does not exist.\n",
    "if not imdb_graph.has_vertex_collection(\"Users\"):\n",
    "    imdb_graph.vertex_collection(\"Users\")\n",
    "\n",
    "# create a new collection named \"Movies\" if it does not exist.\n",
    "# This returns an API wrapper for \"Movies\" collection.\n",
    "if not test_db.has_collection(\"Movies\"):\n",
    "    test_db.create_collection(\"Movies\", replication_factor=3)\n",
    "\n",
    "# Create a new vertex collection named \"Movies\" if it does not exist.\n",
    "if not imdb_graph.has_vertex_collection(\"Movies\"):\n",
    "    imdb_graph.vertex_collection(\"Movies\")\n",
    "\n",
    "# create a new collection named \"Ratings\" if it does not exist.\n",
    "# This returns an API wrapper for \"Ratings\" collection.\n",
    "if not test_db.has_collection(\"Ratings\"):\n",
    "    test_db.create_collection(\"Ratings\", edge=True, replication_factor=3)\n",
    "\n",
    "# creating edge definitions named \"ratings\". This creates any missing\n",
    "# collections and returns an API wrapper for \"ratings\" edge collection.\n",
    "if not imdb_graph.has_edge_definition(\"Ratings\"):\n",
    "    ratings = imdb_graph.create_edge_definition(\n",
    "        edge_collection='Ratings',\n",
    "        from_vertex_collections=['Users'],\n",
    "        to_vertex_collections=['Movies']\n",
    "    )\n",
    "\n",
    "# # create a new collection named \"User_User_Sim\" if it does not exist.\n",
    "if not test_db.has_collection(\"User_User_Sim\"):\n",
    "    test_db.create_collection(\"User_User_Sim\", edge=True, replication_factor=3)\n",
    "\n",
    "# creating edge definitions named \"user_user_sim\". This creates any missing\n",
    "# collections and returns an API wrapper for \"ratings\" edge collection.\n",
    "if not user_user_graph.has_edge_definition(\"User_User_Sim\"):\n",
    "    user_user_sim = user_user_graph.create_edge_definition(\n",
    "        edge_collection='User_User_Sim',\n",
    "        from_vertex_collections=['Users'],\n",
    "        to_vertex_collections=['Users']\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arangorestore is a command-line client tool to restore backups created by Arangodump to ArangoDB servers. \n",
    "Arangorestore can restore selected collections or all collections of a backup, optionally including system collections. One can restore the structure, i.e. the collections with their configuration with or without data. Views can also be dumped or restored (either all of them or selectively)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ./tools/arangorestore -c none --create-collection true --server.endpoint http+ssl://{login[\"hostname\"]}:{login[\"port\"]} --server.username {login[\"username\"]} --server.database {login[\"dbName\"]} --server.password {login[\"password\"]} --default-replication-factor 3  --input-directory \"./imdb_data/data/imdb_with_ratings\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zl19CRTgfKce"
   },
   "outputs": [],
   "source": [
    "# creating a dictionary named as con which will be used to connect to temp database server\n",
    "con = {\"username\": login[\"username\"], \"password\": login[\"password\"],\\\n",
    "       \"dbName\": login[\"dbName\"], \"hostname\": login[\"hostname\"],\\\n",
    "       \"port\": login[\"port\"], \"protocol\": \"https\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HBAq107MfKce"
   },
   "outputs": [],
   "source": [
    "# initialising graph attribues i.e vertices and edges for imdb graph\n",
    "# This will be used to create a graph structure in networkx\n",
    "imdb_attributes = {'vertexCollections': {'Users': {},\n",
    "                                         'Movies': {}},\n",
    "                   'edgeCollections': {'Ratings': {'_from', '_to', 'ratings'}}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtain the Networkx graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RU1NTP8cfKce"
   },
   "outputs": [],
   "source": [
    "from adbnx_adapter.imdb_arangoDB_networkx_adapter import IMDBArangoDB_Networkx_Adapter\n",
    "# Use the new ArangoDB connection with the NetworkX adapter.\n",
    "ma = IMDBArangoDB_Networkx_Adapter(conn=con)\n",
    "g = ma.create_networkx_graph(\n",
    "    graph_name='IMDBGraph',  graph_attributes=imdb_attributes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the user and movie nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YPmJO5FvfKcf"
   },
   "outputs": [],
   "source": [
    "user_nodes = [n for n in g.nodes() if n.startswith(\"Users\")]\n",
    "movie_nodes = [n for n in g.nodes() if n.startswith(\"Movies\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Structural Property Introspection: Number of Nodes and Edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of Users are %d\" % (len(user_nodes)))\n",
    "print(\"Number of Movies are %d\" % (len(movie_nodes)))\n",
    "print(\"Number of Ratings are %d\" % (len(list(g.edges()))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the graph obtained from the interface to a bi-partite graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jrseH95CfKcf"
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "B = nx.Graph()\n",
    "# Add nodes with the node attribute \"bipartite\"\n",
    "B.add_nodes_from(user_nodes, bipartite=0)\n",
    "B.add_nodes_from(movie_nodes, bipartite=1)\n",
    "# Add edges only between nodes of opposite node sets\n",
    "B.add_edges_from(list(g.edges()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: The bipartie clustering coefficient is a measure of local density of connections "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ob91ipxDfKcf"
   },
   "outputs": [],
   "source": [
    "from networkx.algorithms import bipartite\n",
    "# Compute a bipartite clustering coefficient for nodes.\n",
    "cr = bipartite.clustering(B)\n",
    "# stores clustering coefficients for User Nodes\n",
    "cu = {}\n",
    "# stores clustering coefficients for Movies Nodes\n",
    "cm = {}\n",
    "for k, v in sorted(cr.items(),reverse=True, key=lambda item: item[1]):\n",
    "    if k.startswith(\"Users\"):\n",
    "        cu[k] = v\n",
    "    else:\n",
    "        cm[k] = v\n",
    "\n",
    "del cr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Returns the graph G that is the projection of the bipartite graph B onto the specified nodes. We are taking the top 10 user nodes with the highest clustering coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zHUNN1xDfKcf"
   },
   "outputs": [],
   "source": [
    "t10cu = list(cu.keys())[:10]\n",
    "proj_user = nx.bipartite.projected_graph(B, t10cu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating edge collection \"user_user_sim\" using the edges of the above created projected graph (proj_user)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gd924dc2fKcg"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "%time\n",
    "num_embs = proj_user.number_of_nodes()\n",
    "index = 0\n",
    "\n",
    "batch = []\n",
    "BATCH_SIZE = 500\n",
    "batch_idx = 1\n",
    "collection =test_db[\"User_User_Sim\"]\n",
    "# returns all the edges from t10cu nodes to the nodes which are at 1-hop distance \n",
    "el = proj_user.edges()\n",
    "for i, e in enumerate(el):\n",
    "    insert_doc1 = {\"_from\": e[0], \"_to\": e[1]}\n",
    "    insert_doc2 = {\"_from\": e[1], \"_to\": e[0]}\n",
    "    batch.append(insert_doc1)\n",
    "    batch.append(insert_doc2)\n",
    "    index += 2\n",
    "    last_record = (i == (len(el) - 1)) \n",
    "    if index % BATCH_SIZE == 0:\n",
    "        print(\"Inserting batch %d\" % (batch_idx))\n",
    "        batch_idx += 1\n",
    "        collection.import_bulk(batch)\n",
    "        batch = []\n",
    "    if last_record and len(batch) > 0:\n",
    "        print(\"Inserting batch the last batch!\")\n",
    "        collection.import_bulk(batch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying Node2Vec algorithm on the projected graph with a walk length of 10. <br>\n",
    "dimensions - Dimensionality of node2vec embeddings <br>\n",
    "num_walks - Number of walks from each node <br>\n",
    "walk_length - Length of each random walk <br>\n",
    "window_size - Context window size for Word2Vec <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xH00qDdZfKcg"
   },
   "outputs": [],
   "source": [
    "from node2vec import Node2Vec\n",
    "# Precompute probabilities and generate walks\n",
    "node2vec = Node2Vec(proj_user, dimensions=64, walk_length=10, num_walks=10, workers=4)\n",
    "# Embed nodes\n",
    "model = node2vec.fit(window=10, min_count=1, batch_words=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve the the Node2Vec embeddings for each node in proj_user from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RgY4-tY0fKcg"
   },
   "outputs": [],
   "source": [
    "t10cu_emb = { n: list(map(float,model.wv.get_vector(n))) for n in proj_user.nodes()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Storing the node embeddings in the \"Users\" collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rVa-5fGefKcg"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "%time\n",
    "num_embs = proj_user.number_of_nodes()\n",
    "index = 0\n",
    "collection =test_db[\"Users\"]\n",
    "batch = []\n",
    "BATCH_SIZE = 500\n",
    "batch_idx = 1\n",
    "for u, e in t10cu_emb.items():\n",
    "    update_doc = {}\n",
    "    the_key = u.split('/')[1]\n",
    "    update_doc['_id'] = u\n",
    "    update_doc['n2v_emb'] = e\n",
    "    batch.append(update_doc)\n",
    "    index += 1\n",
    "    last_record = (index == (num_embs - 1)) \n",
    "    if index % BATCH_SIZE == 0:\n",
    "        print(\"Inserting batch %d\" % (batch_idx))\n",
    "        batch_idx += 1\n",
    "        collection.update_many(batch)\n",
    "        batch = []\n",
    "    if last_record and len(batch) > 0:\n",
    "        print(\"Inserting batch the last batch!\")\n",
    "        collection.update_many(batch)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Graph_Embeddings.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
