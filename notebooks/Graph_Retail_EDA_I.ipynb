{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/arangodb/interactive_tutorials/blob/master/notebooks/Graph_Retail_EDA_I.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6H0KWq-z9IBd"
   },
   "outputs": [],
   "source": [
    "\n",
    "%%capture\n",
    "!git clone -b retail_data_branch --single-branch https://github.com/arangodb/interactive_tutorials.git\n",
    "!rsync -av  interactive_tutorials/notebooks/data  rsync -av interactive_tutorials/notebooks/tools interactive_tutorials/notebooks/img ./ --exclude=.git\n",
    "!pip install python-arango\n",
    "!pip install arangopipe==0.0.70.0.0\n",
    "!pip install pandas PyYAML==5.1.1 sklearn2\n",
    "!pip install jsonpickle\n",
    "!pip3 install networkx\n",
    "!pip3 install matplotlib\n",
    "!pip3 install adbnx-adapter\n",
    "!chmod a+x tools/* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! cd interactive_tutorials/notebooks\n",
    "! chmod a+x tools/* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o7euPpY6L4e7",
    "outputId": "6b0b825a-1728-4583-8482-ce4180862eac"
   },
   "outputs": [],
   "source": [
    "! wc -l data/online_retail_II.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4F6T33yJiPuA"
   },
   "source": [
    "# Overview\n",
    "\n",
    "Graph analytics can useful in the analysis of retail data. This series of notebook will explore the utility of ideas from graph analytics to analyze data from an online retail store. The store has many infrequent shoppers and a group of loyal shoppers who make purchases at the store often. This study focusses on the group of loyal customers. This group has several attractive features that make it a good candidate to analyze. It is the group for which we have sufficient data describing their shopping behavior. It is also a group that is profitable from business standpoint. They generate revenue for the store. Understanding the shopping preferences of this group can help create better shopping expereiences at the store. See [this article](https://medium.datadriveninvestor.com/why-consumer-behavior-analysis-is-so-relevant-to-the-ecommerce-business-8f49c250ca9c), for example, for some of the reasons why understanding consumer behavior is important in the retail industry. Ideas from graph analytics can be applied to capture critical aspects of customer behavior and product purchase behavior that can leveraged for profit. Extracting analytical insights from the data require, the at the very least, the following:\n",
    "1. Identification of a set of analytical tools that can help extract these insights.\n",
    "2. Transformation of the raw data to a representation that is required by these analytical tools.\n",
    "\n",
    "Graph analytics can be leveraged for the first task. This requires representing the customer purchases at the store in the form of a graph. A particular type of graph structure, a _bi-partite_ graph, is a particularly useful graph representation to extract insights about customer purchasing behavior at the store. Data analysis tools can be leveraged for the second task. The first two notebooks in this series will focus on the data analysis tasks. The next two notebooks will focus on the application of graph analytic tools to extract insights about customer behavior.\n",
    "The data that is analyzed in this series of notebooks are transactions from the store. The data is available in the [UCI ML repository](https://archive.ics.uci.edu/ml/datasets/Online+Retail+II). A schematic illustrating the methodology that will be used in this series of posts is shown below  ![workflow](img/analysis_methodology.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MLYk0_7W-WFo"
   },
   "source": [
    "Consistent with the approach discussed above, the implementation of the notebooks follows a four-step approach. The first two steps illustrate the characteristics of the data and transform the raw data to a form where we can apply graph analytics. The last two steps illustrate the application of ideas from graph analytics to extract insights about customer purchase behavior. The schematic consists of four blocks. The title of each block captures the main functional idea performed by that block. Key features and ideas captured by a functional block are mentioned in the list at the bottom of the block. The representation of the data changes as we work through this four-step process. The circular block elements capture the nature of the data as we work through this process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AGDZAo-iiPuC"
   },
   "source": [
    "## Data Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a1VhFniDiPuD"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "fp = \"data/online_retail_II.csv\"\n",
    "df = pd.read_csv(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dSz4Z2wIiPuE"
   },
   "source": [
    "## List Attributes and Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Oc5BNQt5iPuE",
    "outputId": "b2095120-12b9-443a-d8f8-c116d7dfb0f1"
   },
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0YOC2M93iPuF"
   },
   "source": [
    "### Description of Attributes\n",
    "1. Stockcode: Identifies the goods that are sold at the store. \n",
    "2. Quantity: What kind of counts are associated with purchases.\n",
    "3. Price: Identifies the price of an item.  \n",
    "4. Country: Identifies the country the customer is from.\n",
    "5. Customer ID: Identifies a customer.\n",
    "6. Invoice date: Date of purchase.\n",
    "7. Invoice: Identifies an invoice.\n",
    "8. Description: The description of a stock item."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dHHa209PiPuF"
   },
   "source": [
    "## Data Cleaning\n",
    "These actions prepare the data for further analysis, performing the following:\n",
    "1. Converting attribute types to the correct format where required. In this case, converting the __InvoiceDate__ attribute from string to a datetime type will facilitate downstream analysis based on summaries by time. Customer ID is a float, we will convert this to an integer.\n",
    "2. Removing canceled transactions (documentation with the dataset mention that these transactions are associated with either a 'C' or \"BANK\" prefix in the `Invoice` column)\n",
    "3. Removing transactions with missing data\n",
    "4. Remove transactions where the price for an item is listed as zero\n",
    "\n",
    "These are guidelines from the dataset description and published work by the contributors of this dataset\n",
    "https://link.springer.com/article/10.1057/dbm.2012.17\n",
    "\n",
    "As we clean the data, facts about data quality are logged. Actions that capture data quality capture are tagged with a __Data Quality Metric__ tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xJvvGRxWiPuG"
   },
   "source": [
    "### Convert InvoiceDate to `datetime`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CwkBM36GiPuG"
   },
   "outputs": [],
   "source": [
    "df[\"InvoiceDate\"] = pd.to_datetime(df[\"InvoiceDate\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nPzykajciPuH"
   },
   "source": [
    "### Data Quality Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ROZI9qMM7dea"
   },
   "source": [
    "### Row Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "wv1XFuQoiPuH",
    "outputId": "e4daa903-be63-432c-f541-a9b83ce4d1c4"
   },
   "outputs": [],
   "source": [
    "raw_dataset_number_of_rows = df.shape[0]\n",
    "num_rows_summ = \"Number of rows in the raw dataset: %d\" %(raw_dataset_number_of_rows)\n",
    "num_rows_summ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VixptLjGiPuI"
   },
   "source": [
    "### Data Quality Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VoWGQGQD7jwh"
   },
   "source": [
    "### Cancelled Transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "mHGB8xftiPuI",
    "outputId": "d3a776c5-6df7-49d0-ffe9-96cb846ca8f3"
   },
   "outputs": [],
   "source": [
    "df_c = df[df['Invoice'].str.startswith(\"C\")]\n",
    "df_bank = df[df['StockCode'].str.startswith(\"BANK\")]\n",
    "num_cancelled_returns = df_c.shape[0] + df_bank.shape[0]\n",
    "cancelled_return_summ = \"Cancelled or bank transactions: %d\"%(num_cancelled_returns)\n",
    "cancelled_return_summ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tJrIGEHCiPuI"
   },
   "source": [
    "### Remove Cancelled Transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R6JUi-26iPuI"
   },
   "outputs": [],
   "source": [
    "df = df[-df['Invoice'].str.startswith(\"C\")]\n",
    "df = df[-df['StockCode'].str.startswith(\"BANK\")]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hJoBn_jviPuJ"
   },
   "source": [
    "### Data Quality Metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "92fyiOdV7vbx"
   },
   "source": [
    "### Missing Values\n",
    "Now we check to see if any values are null. If there are null values the shape will report the number of values that are null and column index.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hOhcMaKLiPuJ",
    "outputId": "883f0424-2cde-44de-a1c7-cfa26b86b8ad"
   },
   "outputs": [],
   "source": [
    "df_na = df[pd.isnull(df).any(axis=1)]\n",
    "df_na.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hsaQBmtr740S"
   },
   "source": [
    "We now know at least one column contains null values but the previous statement only stores the first column found. \n",
    "\n",
    "Let's see how many fields have null values and the number of null values per field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "61ZSJj1xiPuJ",
    "outputId": "054f8494-fa57-4f96-b3b6-87a5c6951a52"
   },
   "outputs": [],
   "source": [
    "col_names = df.columns.tolist()\n",
    "missing_val_summ = {}\n",
    "for c in col_names:\n",
    "    num_missing = df[c].isna().sum()\n",
    "    missing_summ = \"Column %s had %d missing values!\" %(c, num_missing)\n",
    "    missing_val_summ[c] = num_missing\n",
    "    print(missing_summ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AWphizpsiPuK"
   },
   "source": [
    "### Remove Transactions with Missing Data\n",
    "Note: It appears that the store has both registered and unregistered customers. Unregistered customers do not have the Customer ID attribute in the transaction record. This analysis is confined to transactions of registered store customers. A small number of store items do not have the description field. These are excluded from the transactions as well. In summary, the transaction data is limited to activities of registered customers and products with descriptions available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mrScdAMtiPuK"
   },
   "outputs": [],
   "source": [
    "df = df.dropna(how ='any')\n",
    "df[\"Customer ID\"] = df[\"Customer ID\"].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kAvbpoEFiPuK"
   },
   "source": [
    "### Data Quality Metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wWPNOukV8GQY"
   },
   "source": [
    "### Zero Price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oWfuW0PDiPuL"
   },
   "source": [
    "Some items have zero price. These transaction line items are dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "A-Md64pviPuL",
    "outputId": "4ee949f7-8fd2-4542-d16f-e09b01b80dd6"
   },
   "outputs": [],
   "source": [
    "dfp0 = df[df[\"Price\"] == 0]\n",
    "zero_price_items = dfp0.shape[0]\n",
    "zero_price_item_msg = \"%d items have zero price value\" % (zero_price_items)\n",
    "zero_price_item_msg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IXPUqNzdiPuL"
   },
   "source": [
    "### Remove Transactions with zero value for Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pLBd0_vtiPuL"
   },
   "outputs": [],
   "source": [
    "df = df[df[\"Price\"] > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ltlneJi0iPuM"
   },
   "source": [
    "## Data Quality Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eQ6k_ffAiPuM"
   },
   "outputs": [],
   "source": [
    "dqm = {}\n",
    "dqm['missing_values'] = missing_val_summ\n",
    "dqm['zero_price'] = zero_price_items\n",
    "dqm['cancelled_bank_transactions'] = num_cancelled_returns\n",
    "# log with arangopipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TKYbVk6WiPuM"
   },
   "source": [
    "## Data Characteristics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aQSIhYGuiPuM"
   },
   "source": [
    "### Derived Attribute, ItemTotal\n",
    "The raw dataset lists the price and the quantiy for each line item, but does not provide a item total which is the product of price and quantity. This attribute is critical in analyzing the purchasing behavior observed at the store. This derived attribute is created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sMFEgSzJiPuN"
   },
   "outputs": [],
   "source": [
    "df[\"ItemTotal\"] = df[\"Price\"] * df[\"Quantity\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Iwnw_5oziPuN"
   },
   "source": [
    "### Number of Customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "YdPoj7BriPuN",
    "outputId": "a7b88f1a-8488-4ae9-bcd7-2d9998239d4f"
   },
   "outputs": [],
   "source": [
    "num_customers = len(df[\"Customer ID\"].unique())\n",
    "num_cust_msg = \"Number of customers: %d\" %(num_customers)\n",
    "num_cust_msg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mHQSDpcKiPuO"
   },
   "source": [
    "### Country of Customer Origin\n",
    "This store has customers from a variety of countries. An overwhelming majority of the customers are from the UK. The analysis will be restricted to customers from the UK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 489
    },
    "id": "-cPLXmL7iPuO",
    "outputId": "a5a9744f-735d-4a7e-abde-3ad3be5f6317"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# Use a dataframe where only one entry is picked for each invoice\n",
    "dfinvgb = df[[\"Invoice\", \"Country\"]].drop_duplicates()\n",
    "plt.figure(figsize=(16, 6))\n",
    "# Turn on the grid\n",
    "dfinvgb[\"Country\"].value_counts().plot.bar(grid = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K7B57qlYiPuO"
   },
   "source": [
    "### Limit to UK customers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LMBzhQRoiPuO"
   },
   "outputs": [],
   "source": [
    "df = df[df[\"Country\"].str.contains('United Kingdom')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "--S8iCsw8cxw"
   },
   "source": [
    "### List the counts of customer origin in the invoices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Aea0bbe9iPuP",
    "outputId": "51295816-e7d1-46e2-bd3f-fd0924884a6b"
   },
   "outputs": [],
   "source": [
    "dfinvgb[\"Country\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Capture Rarely Purchased Stock Items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CUSTOMERS = df[\"Customer ID\"].unique().shape[0]\n",
    "CUT_OFF_SP = 10\n",
    "dfrp = df.groupby([\"StockCode\"]).agg({'Customer ID':['nunique']}).reset_index()\n",
    "dfrp.columns = dfrp.columns.map(''.join)\n",
    "dfrp = dfrp.sort_values(by = \"Customer IDnunique\", ascending = False)\n",
    "dfrp.columns = [\"StockCode\", \"num_cust_purchasing\"]\n",
    "df_rare_purchases = dfrp.query(\"num_cust_purchasing < @CUT_OFF_SP\")\n",
    "rarely_purchased_items = df_rare_purchases[\"StockCode\"].tolist()\n",
    "df = df[-df[\"StockCode\"].isin(rarely_purchased_items)]\n",
    "del df_rare_purchases, dfrp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HTwzthCk5ZKZ"
   },
   "source": [
    "### Diversity in Customer Purchasing Habbits\n",
    "\n",
    "Analysis of the purchase data reveals that there is diversity in the purchasing behavior of customers who shop at the store. This will be illustrated by capturing the patterns in store visits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5TWsYfk1iPuP"
   },
   "source": [
    "### Number of Customer Visits to the Store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cnxjam81iPuP"
   },
   "source": [
    "The Recency-Frequency-Monetary Value is an idea used in the retail domain to analyze customers. See [this article](https://towardsdatascience.com/recency-frequency-monetary-model-with-python-and-how-sephora-uses-it-to-optimize-their-google-d6a0707c5f17) for more details. This idea will be used later in this work. For now, the relevant fact is that the number of customer visits to the store is an important metric in the analysis of retail data. Since we are in an online setting, the number of store visits is approximated as the number of invoices the customer generates at the store. The number of customer visits can be obtained by grouping by customer ID and then counting the number of unique invoices for the customer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rb7Vz4zbiPuP"
   },
   "outputs": [],
   "source": [
    "df_ciph = df.groupby([\"Customer ID\"]).agg({'Invoice':['nunique']}).reset_index()\n",
    "df_ciph.columns = df_ciph.columns.map(''.join)\n",
    "df_ciph = df_ciph.sort_values(by = \"Invoicenunique\", ascending = False)\n",
    "df_ciph.columns = [\"Customer ID\", \"num_invoices\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VmiVRcrCiPuQ"
   },
   "source": [
    "### Observations about customer store visits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TXiBHGJUiPuQ"
   },
   "source": [
    "1. A histogram of customer visits to the store is shown below. A review of this histogram shows that most customers make a small number of store visits, however there are customers that make many visits to the store. Some even make hundreds of store visits. One explanation for this behavior is that store has both retail and wholesale customers. Later in this illustration, a threshold will be used to demarcate wholesale versus the retail customer.\n",
    "2. The quartiles of customer store visit attribute are also shown below. The median number of store visits by a customer is 2. For this analysis, we will consider customers making more than 5 visits to the store as frequent customers.\n",
    "3. In summary, we can broadly divide the store customers into the following categories:\n",
    "  1. Wholesale Customers\n",
    "  2. Frequent Customers (retail)\n",
    "  3. Infrequent Customers (possibly new, retail)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jvk3ct5oiPuQ"
   },
   "source": [
    "### Note:\n",
    "This work will focus of the purchasing behavior of frequent customers. These are customers who make 5 or more visits to the store. Customers who make less than 5 visits to the store are considered customers with insufficient purchase history at the store for this analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "AcVlRFeciPuQ",
    "outputId": "5e534ee7-5eb9-4175-bb62-ef1e2f6eb992"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 6))\n",
    "df_ciph[\"num_invoices\"].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iqufhBqriPuQ",
    "outputId": "f1e7268c-4f4f-4fbe-d3a3-80c0bdf0e33b"
   },
   "outputs": [],
   "source": [
    "df_ciph[\"num_invoices\"].quantile(q = [0.2, 0.4, 0.5, 0.8, 0.9, 0.95])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pAJQOcAdiPuR"
   },
   "source": [
    "### Observations about Item Prices at the store\n",
    "Most items at the store are cheap. The median price of an item is less than 2 pounds. The summary of the _Price_ attribute is shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q1y7zcYLiPuR",
    "outputId": "84f1bb98-73d7-4de0-f975-e7c17293f6df"
   },
   "outputs": [],
   "source": [
    "df[\"Price\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BKhrN4YFiPuR"
   },
   "source": [
    "### Invoice Line Item Purchase Value\n",
    "As discussed in the observations about the number of customer visits, the store has both retail and whole sale customers. Going with a definition of a whole customer as one who purchases a lot of a particular store item, we will use a threshold value of _ItemTotal_ to capture invoices that are associated with whole sale purchases. Most store items are cheap, with the median value being less than 2 pounds. We will use the $95^{th}$ percentile of this attribute as a threshold value to capture a whole sale purchase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Heavy Spenders\n",
    "These are outliers, we remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spend = df.groupby([\"Invoice\"]).agg({'ItemTotal':['sum']}).reset_index()\n",
    "df_spend.columns = df_spend.columns.map(''.join)\n",
    "HEAVY_SPENDERS_95_LVL = df_spend[\"ItemTotalsum\"].quantile(q = [0.95]).values[0]\n",
    "df_heavy_spenders = df_spend.query(\"ItemTotalsum > @HEAVY_SPENDERS_95_LVL\")\n",
    "high_total_invoices = df_heavy_spenders[\"Invoice\"].tolist()\n",
    "df_hs = df[df[\"Invoice\"].isin(high_total_invoices)]\n",
    "df = df[-df[\"Invoice\"].isin(high_total_invoices)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F6UsoVBhiPuR"
   },
   "source": [
    "### Remove wholesale customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "krkmi0VhiPuS"
   },
   "outputs": [],
   "source": [
    "ITEM_TOTAL_95_LVL = df[\"ItemTotal\"].quantile(q = [0.95]).iloc[0]\n",
    "df_ws = df.query(\"ItemTotal >= @ITEM_TOTAL_95_LVL\")\n",
    "ws_invoices = df_ws[\"Invoice\"].tolist()\n",
    "df = df[-df[\"Invoice\"].isin(ws_invoices)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZGrHl_geiPuS"
   },
   "source": [
    "### Remove customers with low purchase history (retain only frequent shoppers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "15GM-YGRiPuS"
   },
   "outputs": [],
   "source": [
    "df_ciph = df.groupby([\"Customer ID\"]).agg({'Invoice':['nunique']}).reset_index()\n",
    "df_ciph.columns = df_ciph.columns.map(''.join)\n",
    "df_ciph = df_ciph.sort_values(by = \"Invoicenunique\", ascending = False)\n",
    "df_ciph.columns = [\"Customer ID\", \"num_invoices\"]\n",
    "INSUFF_PURCHASE_HISTORY_LVL = 5\n",
    "df_ciph = df_ciph.query(\"num_invoices < @INSUFF_PURCHASE_HISTORY_LVL\")\n",
    "insuff_purch_hist = df_ciph[\"Customer ID\"].tolist()\n",
    "df = df[-df[\"Customer ID\"].isin(insuff_purch_hist)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MOOa7ArG85SE"
   },
   "source": [
    "### Customer Populations\n",
    "In this work, we will be analyzing the group of customers who make frequent purchases at the store. By analyzing the whole sale customers and the infrequent shopper group, also using graph analytic techniques, we can generate a comprehensive profile of the customers visiting the store."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QmDByE1piPuS"
   },
   "source": [
    "## User Utility Matrix Computation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DmVrf1_JiPuT"
   },
   "source": [
    "A common data representation of customer purchasing habbits used in retail applications is one where each user is represented by his purchases of the various items at the store. Such a representation has a tabular structure where each user is a row in the table. This representation is called the _user-item utility matrix_ . The columns represent the aggregate purchases of the various items at the store. The __Recency_Frequency_Monetary Value__ concept is used to capture the value of a user. Therefore, in addition to the purchases. These attributes are captured as well. The _Recency_ attribute captures the time from a reference data since the user's last visit. The _Frequency_ attribute captures the number of visits made by the customer to the store. The _Monetary Value_ captures the customer's cumulative spend at the store. A schematic illustrating the _user-item utility matrix_ is shown below. The details of computation of this matrix follow ![UI-Utility-Matrix](img/user_item_matrix_schematic.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nxPGtLMCiPuT"
   },
   "source": [
    "The _user-item utility matrix_ can be computed from the data using the _pivot-table_ construct with the customer as the index column and the sum applied to the _ItemTotal_ attribute. The details of the computation are shown below. The default implementation puts NaN values for items where the user has not made a purchase. These are filled out as zeros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z7ZdcwfxiPuT"
   },
   "source": [
    "### User Item Interaction\n",
    "To understand the nature of a customers interaction with store items, let us compute the number of items a customer interacts with over a lifetime of purchases at the store. The summary statistics of this attribute is shown below. As is evident, the median value for the interaction is about 110 items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MS6edQ5iiPuT",
    "outputId": "5ffffdd9-86f9-459a-c796-eaff642f0713"
   },
   "outputs": [],
   "source": [
    "df_item_cust = df.groupby([\"Customer ID\"]).agg({'StockCode':['nunique']}).reset_index()\n",
    "df_item_cust.columns = df_item_cust.columns.map(''.join)\n",
    "df_item_cust = df_item_cust.sort_values(by = \"StockCodenunique\", ascending = False)\n",
    "df_item_cust.columns = [\"Customer ID\", \"num_item_types_purchased\"]\n",
    "df_item_cust[\"num_item_types_purchased\"].quantile(q = [0.2, 0.4, 0.5, 0.8, 0.9, 0.95])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "67hr6n3siPuU"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "df_customer_summary = df.groupby([\"Customer ID\", \"StockCode\"]).\\\n",
    "agg({'ItemTotal':['sum']}).reset_index()\n",
    "df_customer_summary.columns = df_customer_summary.columns.map(''.join)\n",
    "df_customer_report  = df_customer_summary.pivot(index='Customer ID', columns='StockCode', values='ItemTotalsum')\n",
    "df_customer_report = df_customer_report.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F31-Cyi3iPuU"
   },
   "source": [
    "## Feature Selection with Linear Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ICsMrfcviPuU"
   },
   "source": [
    "One of the objectives for this work is to understand the frequent shopper groups preferences for store items. An intrinsic feature of the user-item utility matrix is that a user is a high-dimensional representation. The frequent shopper group purchases  2765  store items. The median value of items a customer purchases at the store is  110 . The dimensionality on the other hand is  2765 . This implies that for most customers, the representation is going to have a high proportion of zero values. Such a representation is called a sparse representation. Since one of the objectives of this work is to understand the nature of customer shopping preferences, a feature selection model based on a linear regression model is used to identify the pool of store items that can capture the customer value at the store. The details of developing this model are provided in the next set of illustration. In developing the data representation of the customer, a data preparation step in light of this downstream modeling activity is relavant. This step pertains to removing correlated attributes from the customer representation. Linear models are affected by a phenomenon called multi-collinearity, a condition that manifests when we have attributes that are highly correlated with each other. Multi-collinearity presents computational difficulties in estimating linear models. To prevent multi-collinearity, when we have highly correlated columns, we retain one of the columns and drop the other. In this work a threshold of  0.8  is used to screen the correlated columns in the user-item utility matrix. The details of removing the correlated items are shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UaFN_D4AiPuU",
    "outputId": "0c5c679a-af93-4449-a390-23beee9b3ca4"
   },
   "outputs": [],
   "source": [
    "dfsclu = df[[\"StockCode\", \"Description\"]].drop_duplicates()\n",
    "print(\"Computing correlations...\")\n",
    "df_corr = df_customer_report.corr()\n",
    "cols = df_corr.columns.tolist()\n",
    "high_corr = dict()\n",
    "THRESHOLD_CORR = 0.8\n",
    "\n",
    "for index, row in df_corr.iterrows():\n",
    "    for c in cols:\n",
    "        if (row[c] > THRESHOLD_CORR) and (index != c):\n",
    "            if not (c, index) in high_corr:\n",
    "                high_corr[(index, c)] = row[c]\n",
    "\n",
    "drop_cols = []\n",
    "print(\"Creating the list of columns to drop on the basis of high correlation...\")\n",
    "for k, v in high_corr.items():\n",
    "    drop_cols.append(k[1])\n",
    "\n",
    "print(\"Creating a description of highly correlated columns for analysis...\")\n",
    "hc_df_dict = {'var_1': [], 'desc_1': [], 'var_2': [], 'desc_2': [], 'corr':[]}\n",
    "for k, v in high_corr.items():\n",
    "    hc_df_dict[\"var_1\"].append(k[0])\n",
    "    trimstr = dfsclu.loc[dfsclu[\"StockCode\"] == k[0]][\"Description\"].values[0]\n",
    "    trimstr = trimstr.replace(\" \", \"_\")\n",
    "    hc_df_dict[\"desc_1\"].append(trimstr)\n",
    "    hc_df_dict[\"var_2\"].append(k[1])\n",
    "    trimstr = dfsclu.loc[dfsclu[\"StockCode\"] == k[1]][\"Description\"].values[0]\n",
    "    trimstr = trimstr.replace(\" \", \"_\")\n",
    "    hc_df_dict[\"desc_2\"].append(trimstr)\n",
    "    hc_df_dict[\"corr\"].append(v)\n",
    "\n",
    "df_high_corr_var = pd.DataFrame.from_dict(hc_df_dict, orient='index').T\n",
    "fp_hci = \"data/highly_correlated_items.csv\"\n",
    "df_high_corr_var.to_csv(fp_hci, index = False)\n",
    "print(\"Removing the list of highly correlated columns...\")\n",
    "cols = df_customer_report.columns.tolist()\n",
    "ucol = [c for c in cols if c not in drop_cols]\n",
    "df_customer_report = df_customer_report[ucol]\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wo5_ZvrMiPuV"
   },
   "source": [
    "## Recency, Frequency and Monetary-Value computation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "caKV4hqIiPuV"
   },
   "source": [
    "The details of computing the __recency__, __frequency__ and __monetary value__ attributes for the customer are shown below. \n",
    "1. _recency_ : The _recency_  attribute captures the time that has elapsed since the customer's last visit to the store. To compute this, the most recent date in the data is used as a reference date. The time period that has elapsed between the customer's last visit to the store, as available from the customer's newest invoice,  and this reference date represents the time interval, $\\Delta T$, between the customer's last visit and the reference data. This time interval, $\\Delta T$, does not have the qualities we want from an attribute that captures recency. $\\Delta T$, is small for customers whose last visit is very close to the most recent date and large for customers whose last vist is a large time period from the most recent date. We want the recency attribute to have the opposite of this behavior. Customers who visited the store close to the most recent date should have a high value and customers who visited store a while from the most recent date should have a low value. We can get this characteristic by defining: $$recency = \\frac{1}{\\Delta T}$$.   \n",
    "2. _frequency_ : The _frequency_ attribute captures the number of purchases the customer has made at the store. This directly maps to the number of invoices generated by the customer, so computing this attribute translates to simply counting the number of invoices for the customer.\n",
    "3. _monetary value_ : The _monetary value_ captures the amount of money the customer has spent at the store. This can be computed by aggregating the invoice line item totals for all the customer's invoices. \n",
    "\n",
    "Computing these attributes can be performed easily with the _groupby_ and _agg_ functions available in _pandas_. The details of the computation are shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KRrVjVgUiPuV"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "ref_date = df[\"InvoiceDate\"].max() + pd.DateOffset(days=1)\n",
    "dfcustlv = df.groupby([\"Customer ID\"]).agg({'InvoiceDate':['max']}).reset_index()\n",
    "dfcustlv.columns = dfcustlv.columns.map(''.join)\n",
    "dfcustlv.columns = [\"Customer ID\", \"last_visit_date\"]\n",
    "dfcustlv = dfcustlv.set_index(\"Customer ID\")\n",
    "dfcustlv[\"recency\"] = (ref_date - dfcustlv[\"last_visit_date\"])/np.timedelta64(1,'D')\n",
    "dfcustlv[\"recency\"] = 1/ dfcustlv[\"recency\"]\n",
    "dfcustlv = dfcustlv[\"recency\"]\n",
    "dfcustlv.columns = [\"recency\"]\n",
    "\n",
    "df_freq = df.groupby([\"Customer ID\"]).agg({'Invoice':['nunique']}).reset_index()\n",
    "df_freq.columns = df_freq.columns.map(''.join)\n",
    "df_freq = df_freq.set_index(\"Customer ID\")\n",
    "df_freq.columns = [\"freq\"]\n",
    "\n",
    "dfum = df.groupby([\"Customer ID\"]).agg({'ItemTotal' :['sum']}).reset_index()\n",
    "dfum.columns = dfum.columns.map(''.join)\n",
    "dfum.columns = [\"Customer ID\", \"MonetaryValue\"]\n",
    "dfum = dfum.set_index(\"Customer ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "90WDj2EMiPuV",
    "outputId": "ef707cc1-7bd7-46fa-9aa7-64e8a9eaa739"
   },
   "outputs": [],
   "source": [
    "df_customer_report = pd.concat([df_customer_report, dfum], axis = 1)\n",
    "df_customer_report = pd.concat([df_customer_report, df_freq], axis = 1)\n",
    "df_customer_report = pd.concat([df_customer_report, dfcustlv], axis = 1)\n",
    "#HIGH_VALUE_CUST_LVL = df_customer_report[\"MonetaryValue\"].quantile(q = [0.95]).values[0]\n",
    "#df_customer_report = df_customer_report.query(\"MonetaryValue <= @HIGH_VALUE_CUST_LVL\")\n",
    "print (\"Writing data file...\")\n",
    "fp = \"data/user_item_utility_matrix.csv\"\n",
    "df_customer_report.to_csv(fp)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6exGchnuH_gS"
   },
   "source": [
    "# Log Model Building Meta-Data with Arangopipe\n",
    "Arangopipe is a tool to capture meta-data from data science project activities. See the [the project repository](https://github.com/arangoml/arangopipe) for more details. See [this notebook](https://github.com/arangoml/arangopipe/blob/master/examples/Arangopipe_Feature_Examples.ipynb) for an overview of the basic steps involved in capturing datascience project activity meta-data with Arangopipe. The cells below capture the meta-data from the exploratory data analysis task with Arangopipe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LfZgJ5UmDJv9"
   },
   "source": [
    "###  Create an Arangopipe Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M1lpkpmaDH81",
    "outputId": "ff6477e2-d0c7-42d7-b9be-1180b3ea19ba"
   },
   "outputs": [],
   "source": [
    "from arangopipe.arangopipe_storage.arangopipe_api import ArangoPipe\n",
    "from arangopipe.arangopipe_storage.arangopipe_admin_api import ArangoPipeAdmin\n",
    "from arangopipe.arangopipe_storage.arangopipe_config import ArangoPipeConfig\n",
    "from arangopipe.arangopipe_storage.managed_service_conn_parameters import ManagedServiceConnParam\n",
    "mdb_config = ArangoPipeConfig()\n",
    "msc = ManagedServiceConnParam()\n",
    "conn_params = { msc.DB_SERVICE_HOST : \"arangoml.arangodb.cloud\", \\\n",
    "                        msc.DB_SERVICE_END_POINT : \"createDB\",\\\n",
    "                        msc.DB_SERVICE_NAME : \"createDB\",\\\n",
    "                        msc.DB_SERVICE_PORT : 8529,\\\n",
    "                        msc.DB_CONN_PROTOCOL : 'https',\\\n",
    "                        msc.DB_REPLICATION_FACTOR: 3}\n",
    "        \n",
    "mdb_config = mdb_config.create_connection_config(conn_params)\n",
    "admin = ArangoPipeAdmin(reuse_connection = False, config = mdb_config)\n",
    "ap_config = admin.get_config()\n",
    "ap = ArangoPipe(config = ap_config)\n",
    "proj_info = {\"name\": \"Retail_Graph_Analytics\"}\n",
    "proj_reg = admin.register_project(proj_info)\n",
    "mdb_config.get_cfg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = mdb_config.get_cfg()['arangodb']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AWDeKf9HDmF4"
   },
   "source": [
    "### Register Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cHFPleUHDlTO"
   },
   "outputs": [],
   "source": [
    "ds_info = {\"name\" : \"retail analytics dataset\",\\\n",
    "            \"description\": \"This dataset lists details of invoices generated at an online store selling gift items in the UK\",\\\n",
    "           \"source\": \"UCI ML Repository\" }\n",
    "ds_reg = ap.register_dataset(ds_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HRt-ybmSEYMz"
   },
   "source": [
    "### Register the Featureset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PmBJbPTXD8hK"
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "featureset = df.dtypes.to_dict()\n",
    "featureset = {k:str(featureset[k]) for k in featureset}\n",
    "featureset[\"name\"] = \"retail analytics feature setl\"\n",
    "fs_reg = ap.register_featureset(featureset, ds_reg[\"_key\"]) # note that the dataset and featureset are linked here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5A3s-sQkEoWE"
   },
   "source": [
    "### Register this Exploratory Data Analysis Task with Arangopipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ak0BbDX8EwK4"
   },
   "outputs": [],
   "source": [
    "model_info = {\"name\": \"Exploratory Data Analysis, phase I\",  \"task\": \"EDA\"}\n",
    "model_reg = ap.register_model(model_info, project = \"Retail_Graph_Analytics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-iYiwjUbHl2W"
   },
   "source": [
    "### Log Exploratory Data Analysis Task with Arangopipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7wnZ9kEkFgL4"
   },
   "outputs": [],
   "source": [
    "import uuid\n",
    "import datetime\n",
    "import jsonpickle\n",
    "\n",
    "ruuid = str(uuid.uuid4().int)\n",
    "qme = jsonpickle.encode(dqm)\n",
    "model_perf = {'run_id': ruuid, 'quality_metrics': qme, \"timestamp\": str(datetime.datetime.now())}\n",
    "\n",
    "model_params = {'run_id': ruuid, 'model_params': 'NA'}\n",
    "\n",
    "run_info = {\"dataset\" : ds_reg[\"_key\"],\\\n",
    "                    \"featureset\": fs_reg[\"_key\"],\\\n",
    "                    \"run_id\": ruuid,\\\n",
    "                    \"model\": model_reg[\"_key\"],\\\n",
    "                    \"model-params\": model_params,\\\n",
    "                    \"model-perf\": model_perf,\\\n",
    "                    \"tag\": \"Retail_Graph_Analytics\",\\\n",
    "                    \"project\": \"Retail_Graph_Analytics\"}\n",
    "ap.log_run(run_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!./tools/arangodump  -c none --server.endpoint http+ssl://{conn[\"DB_service_host\"]}:{conn[\"DB_service_port\"]} --server.username {conn[\"username\"]} --server.database {conn[\"dbName\"]} --server.password {conn[\"password\"]} --overwrite true --output-directory \"data/retail_freq_cust_data_dump_eonb1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to export the connection the information to OASIS to a config file, you may do so as:\n",
    "# fp = \"data/ap_config_retail.yaml\"\n",
    "# ap_config.export_cfg(fp)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "tJrIGEHCiPuI",
    "IXPUqNzdiPuL",
    "aQSIhYGuiPuM",
    "Jvk3ct5oiPuQ",
    "BKhrN4YFiPuR",
    "F6UsoVBhiPuR",
    "Z7ZdcwfxiPuT"
   ],
   "name": "graph_retail_EDA_I.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
