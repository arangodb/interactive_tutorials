{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {
    "id": "c94240f5"
   },
   "source": [
    "# ArangoDB ðŸ¥‘ + LangChain ðŸ¦œðŸ”— (Basics)\n",
    "\n",
    "[![Open In Collab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/arangodb/interactive_tutorials/blob/master/notebooks/Langchain.ipynb)\n",
    "\n",
    "**Looking for the full notebook? Check out [LangChain_Full.ipynb](https://colab.research.google.com/github/arangodb/interactive_tutorials/blob/master/notebooks/Langchain_Full.ipynb).**\n",
    "\n",
    "Large language models (LLMs) are emerging as a transformative technology, enabling developers to build applications that they previously could not. However, using these LLMs in isolation is often insufficient for creating a truly powerful app - the real power comes when you can combine them with other sources of computation or knowledge.\n",
    "\n",
    "[LangChain](https://www.langchain.com/) is a framework for developing applications powered by language models. It enables applications that are:\n",
    "- Data-aware: connect a language model to other sources of data\n",
    "- Agentic: allow a language model to interact with its environment\n",
    "\n",
    "On July 25 2023, ArangoDB introduced the first release of the [ArangoGraphQAChain](https://langchain-langchain.vercel.app/docs/integrations/providers/arangodb) to the LangChain community, allowing you to leverage LLMs to provide a natural language interface for your ArangoDB data.\n",
    "\n",
    "**Please note**: This notebook uses the LangChain `ChatOpenAI` wrapper, which requires you to have a **paid** [OpenAI API Key](https://help.openai.com/en/articles/4936850-where-do-i-find-my-secret-api-key). However, other Chat Models are available as well: https://github.com/langchain-ai/langchain/tree/master/libs/langchain/langchain/chat_models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {
    "id": "WejTADc2L72f"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {
    "id": "izi6YoFC8KRH"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "# 1: Install the dependencies\n",
    "\n",
    "!pip install python-arango # The ArangoDB Python Driver\n",
    "!pip install adb-cloud-connector # The ArangoDB Cloud Instance provisioner\n",
    "!pip install arango-datasets # Datasets package\n",
    "!pip install openai==1.6.1\n",
    "!pip install langchain==0.1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {
    "id": "62812aad"
   },
   "outputs": [],
   "source": [
    "# 2: Provision a temporary ArangoDB Cloud instance\n",
    "\n",
    "from adb_cloud_connector import get_temp_credentials\n",
    "\n",
    "connection = get_temp_credentials(tutorialName=\"LangChain\")\n",
    "\n",
    "connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {
    "id": "0928915d"
   },
   "outputs": [],
   "source": [
    "# 3: Instantiate the ArangoDB-Python driver\n",
    "\n",
    "from arango import ArangoClient\n",
    "\n",
    "client = ArangoClient(hosts=connection[\"url\"])\n",
    "\n",
    "db = client.db(\n",
    "    connection[\"dbName\"],\n",
    "    connection[\"username\"],\n",
    "    connection[\"password\"],\n",
    "    verify=True\n",
    ")\n",
    "\n",
    "db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {
    "id": "fedd26b9"
   },
   "outputs": [],
   "source": [
    "# 4: Load sample data\n",
    "# We'll be relying on our Game Of Thrones dataset, representing the parent-child\n",
    "# relationships of certain characters from the GoT universe\n",
    "\n",
    "from arango_datasets import Datasets\n",
    "\n",
    "Datasets(db).load(\"GAME_OF_THRONES\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {
    "id": "4e3de44f"
   },
   "outputs": [],
   "source": [
    "# 5: Instantiate the ArangoDB-LangChain Graph wrapper\n",
    "\n",
    "from langchain.graphs import ArangoGraph\n",
    "\n",
    "graph = ArangoGraph(db)\n",
    "\n",
    "graph.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {
    "id": "mZ679anj_-Er"
   },
   "outputs": [],
   "source": [
    "# 6: Set your OpenAI API Key\n",
    "# https://help.openai.com/en/articles/4936850-where-do-i-find-my-secret-api-key\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {
    "id": "V1PMxRubKxmK"
   },
   "outputs": [],
   "source": [
    "# 7: Instantiate the OpenAI Chat model\n",
    "# Note that other models can be used as well\n",
    "# Ref: https://github.com/langchain-ai/langchain/tree/master/libs/langchain/langchain/chat_models\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(temperature=0, model_name='gpt-4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {
    "id": "7476ce98"
   },
   "outputs": [],
   "source": [
    "# 8: Instantiate the LangChain Question-Answering Chain with\n",
    "# our **model** and **graph**\n",
    "\n",
    "from langchain.chains import ArangoGraphQAChain\n",
    "\n",
    "chain = ArangoGraphQAChain.from_llm(model, graph=graph, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {
    "id": "MdTyIwWeL953"
   },
   "source": [
    "## Prompting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {
    "id": "e9f92bb2"
   },
   "source": [
    "\"Prompting\" is the process of providing a language model with a set of text-based instructions to achieve some arbitrary output. The text can be as simple as a single word, or as complex as a full paragraph. The model is responsible for generating a response based on the content of the prompt.\n",
    "\n",
    "This section will utilize the [ChatOpenAI](https://python.langchain.com/docs/integrations/chat/openai) wrapper under the hood to translate Natural Language into ArangoDB Query Language (AQL) queries. In fact, the `chain` object we've created is responsible for the following steps:\n",
    "1. Translate the Natural Language Prompt into an AQL Query\n",
    "2. Execute the AQL Query against the ArangoDB database to retrieve a JSON Result\n",
    "3. If a query error occurs, go back to step 1 with a modified prompt to include the error message\n",
    "3. Translate the JSON Result to a Natural Language answer\n",
    "\n",
    "Let's take a look at how this works in practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {
    "id": "ef8ee27b"
   },
   "outputs": [],
   "source": [
    "chain.invoke(\"Who are the 2 youngest characters?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {
    "id": "9CSig1BgA76q"
   },
   "outputs": [],
   "source": [
    "chain.invoke(\"How are Bran Stark and Arya Stark related?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {
    "id": "9Fzdic_pA_4y"
   },
   "outputs": [],
   "source": [
    "chain.invoke(\"Who are Bran Starkâ€™s grandparents?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {
    "id": "zq_oeDpAOXpF"
   },
   "outputs": [],
   "source": [
    "chain.invoke(\"Fetch me the character count for each family\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {
    "id": "Qfi_e1_P_tKj"
   },
   "outputs": [],
   "source": [
    "chain.invoke(\"What is the age difference between Rickard Stark and Arya Stark?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {
    "id": "pjTLW6ct_71q"
   },
   "outputs": [],
   "source": [
    "chain.invoke(\"Wie alt ist Rickard Stark?\") # (German: \"How old is Rickard Stark?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {
    "id": "-VfkVtt4_9FK"
   },
   "outputs": [],
   "source": [
    "chain.invoke(\"What is the average age within the Stark family?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {
    "id": "89-QJ87m__ol"
   },
   "outputs": [],
   "source": [
    "chain.invoke(\"Does Bran Stark have a dead parent?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {
    "id": "MV6ENBJVAB-w"
   },
   "outputs": [],
   "source": [
    "chain.invoke(\"Who are Catelyn Stark's children?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {
    "id": "_2maN0_sAFCO"
   },
   "outputs": [],
   "source": [
    "chain.invoke(\"Add Jon Snow, 31, a male character\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {
    "id": "_MHWiAVeM3Cg"
   },
   "outputs": [],
   "source": [
    "chain.invoke(\"Create a ChildOf edge from Jon Snow to Ned Stark\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {
    "id": "3mU0MyGsM6gX"
   },
   "outputs": [],
   "source": [
    "chain.invoke(\"Who is related to Ned Stark?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {
    "id": "jpK1CTypN0s6"
   },
   "outputs": [],
   "source": [
    "chain.invoke(\"What can you tell me about the characters?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {
    "id": "rjJd8BCMN6TE"
   },
   "outputs": [],
   "source": [
    "chain.invoke(\"What is the shortest path from Bran Stark to Rickard Stark?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {
    "id": "h1OgY3LbOZmI"
   },
   "outputs": [],
   "source": [
    "chain.invoke(\"What is th family tree of Joffrey Baratheon?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {
    "id": "BOcwm5eIN795"
   },
   "outputs": [],
   "source": [
    "chain.invoke(\"What is the relationship between Bran Stark and Rickard Stark?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {
    "id": "vxZYOwH5ORVp"
   },
   "outputs": [],
   "source": [
    "chain.invoke(\"Are Arya Stark and Ned Stark related?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {
    "id": "0qYH7IG1OWFm"
   },
   "outputs": [],
   "source": [
    "chain.invoke(\"Is Ned Stark alive?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {
    "id": "H_k57SLRODIv"
   },
   "outputs": [],
   "source": [
    "chain.invoke(\"Ned Stark has died. Update the data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {
    "id": "ghVJEfZuOMcK"
   },
   "outputs": [],
   "source": [
    "chain.invoke(\"How many characters are alive? How many characters are dead?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {
    "id": "NmR7P693ONPl"
   },
   "outputs": [],
   "source": [
    "chain.invoke(\"Is Arya Stark an orphan?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {
    "id": "Ob_3aGauGd7d"
   },
   "source": [
    "## Prompt Modifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {
    "id": "a486450e"
   },
   "source": [
    "[Prompt Engineering](https://en.wikipedia.org/wiki/Prompt_engineering) can be defined as process of improving a prompt to achieve a better result from a language model.\n",
    "\n",
    "The `chain` object comes with a set of built-in prompt modifiers that can be used to improve the quality of the results. These modifiers are:\n",
    "- `top_k`: Limit the maximum number of results returned by the AQL Query execution\n",
    "- `max_aql_generation_attempts`: Limit the maximum number of times the AQL Query is generated before giving up (i.e if the query is invalid)\n",
    "- `return_aql_query`: Return the AQL Query as part of the output dictionary (useful for debugging)\n",
    "- `return_aql_result`: Return the AQL Query Result as part of the output dictionary (useful for debugging)\n",
    "- `aql_examples`: A list of AQL Examples for the model to learn from when generating the next AQL Query. This is a powerful tool for teaching the model how to generate AQL Queries for your specific dataset.\n",
    "\n",
    "Let's start by looking at the `aql_examples` modifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {
    "id": "Q7zxc0kBPhpg"
   },
   "outputs": [],
   "source": [
    "# Notice how the following prompt returns nothing;\n",
    "chain.invoke(\"Who are the grandchildren of Rickard Stark?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {
    "id": "zoxZwQh5Pj4J"
   },
   "outputs": [],
   "source": [
    "# This is because the wrong AQL Traversal direction is used! LLMs can hallucinate..\n",
    "# A simple reminder to use INBOUND (instead of OUTBOUND) returns the correct result;\n",
    "chain.invoke(\"Who are the grandchildren of Rickard Stark? Remember to use INBOUND\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {
    "id": "7WHxkGPPPk8-"
   },
   "outputs": [],
   "source": [
    "# We can solidify this pattern by making using of **chain.aql_examples**\n",
    "\n",
    "# The AQL Examples modifier instructs the LLM to adapt its AQL-completion style\n",
    "# to the userâ€™s examples. These examples are passed to the AQL Generation Prompt\n",
    "# Template to promote few-shot-learning.\n",
    "\n",
    "chain.aql_examples = \"\"\"\n",
    "# Who are the grandchildren of Rickard Stark?\n",
    "WITH Characters, ChildOf\n",
    "FOR v, e IN 2..2 INBOUND 'Characters/RickardStark' ChildOf\n",
    "  RETURN v\n",
    "\n",
    "# Is Ned Stark alive?\n",
    "RETURN DOCUMENT('Characters/NedStark').alive\n",
    "\n",
    "...\n",
    "\"\"\"\n",
    "\n",
    "# Note how we are no longer specifying the use of INBOUND\n",
    "chain.invoke(\"Who is the grandchildren of Tywin Lannister?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {
    "id": "1B9h3PvzJ41T"
   },
   "outputs": [],
   "source": [
    "# Other modifiers include:\n",
    "\n",
    "# Specify the maximum number of AQL Query Results to return\n",
    "chain.top_k = 5\n",
    "\n",
    "# Specify the maximum amount of AQL Generation attempts that should be made\n",
    "# before returning an error\n",
    "chain.max_aql_generation_attempts = 5\n",
    "\n",
    "# Specify whether or not to return the AQL Query in the output dictionary\n",
    "# Use `chain(\"...\")` instead of `chain.invoke(\"...\")` to see this change\n",
    "chain.return_aql_query = True\n",
    "\n",
    "# Specify whether or not to return the AQL JSON Result in the output dictionary\n",
    "# Use `chain(\"...\")` instead of `chain.invoke(\"...\")` to see this change\n",
    "chain.return_aql_result = True"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
