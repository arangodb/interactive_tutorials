{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c94240f5",
   "metadata": {
    "id": "c94240f5"
   },
   "source": [
    "# ArangoDB ðŸ¥‘ + LangChain ðŸ¦œðŸ”— (Basics)\n",
    "\n",
    "[![Open In Collab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/arangodb/interactive_tutorials/blob/master/notebooks/Langchain.ipynb)\n",
    "\n",
    "**Looking for the full notebook? Check out [LangChain_Full.ipynb](https://colab.research.google.com/github/arangodb/interactive_tutorials/blob/master/notebooks/Langchain_Full.ipynb).**\n",
    "\n",
    "Large language models (LLMs) are emerging as a transformative technology, enabling developers to build applications that they previously could not. However, using these LLMs in isolation is often insufficient for creating a truly powerful app - the real power comes when you can combine them with other sources of computation or knowledge.\n",
    "\n",
    "[LangChain](https://www.langchain.com/) is a framework for developing applications powered by language models. It enables applications that are:\n",
    "- Data-aware: connect a language model to other sources of data\n",
    "- Agentic: allow a language model to interact with its environment\n",
    "\n",
    "On July 25 2023, ArangoDB introduced the first release of the [ArangoGraphQAChain](https://langchain-langchain.vercel.app/docs/integrations/providers/arangodb) to the LangChain community, allowing you to leverage LLMs to provide a natural language interface for your ArangoDB data.\n",
    "\n",
    "**Please note**: This notebook uses the LangChain `ChatOpenAI` wrapper, which requires you to have a **paid** [OpenAI API Key](https://help.openai.com/en/articles/4936850-where-do-i-find-my-secret-api-key). However, other Chat Models are available as well: https://github.com/langchain-ai/langchain/tree/master/libs/langchain/langchain/chat_models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "WejTADc2L72f",
   "metadata": {
    "id": "WejTADc2L72f"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "izi6YoFC8KRH",
   "metadata": {
    "id": "izi6YoFC8KRH"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "# 1: Install the dependencies\n",
    "\n",
    "!pip install python-arango # The ArangoDB Python Driver\n",
    "!pip install adb-cloud-connector # The ArangoDB Cloud Instance provisioner\n",
    "!pip install arango-datasets # Datasets package\n",
    "!pip install openai==1.6.1\n",
    "!pip install langchain==0.1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62812aad",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "62812aad",
    "outputId": "5e531c1a-ef0a-40ea-ea59-e77ee4723b47"
   },
   "outputs": [],
   "source": [
    "# 2: Provision a temporary ArangoDB Cloud instance\n",
    "\n",
    "from adb_cloud_connector import get_temp_credentials\n",
    "\n",
    "connection = get_temp_credentials(tutorialName=\"LangChain\")\n",
    "\n",
    "connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0928915d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0928915d",
    "outputId": "3d79089f-759a-4d9d-9b96-726e11c2831d"
   },
   "outputs": [],
   "source": [
    "# 3: Instantiate the ArangoDB-Python driver\n",
    "\n",
    "from arango import ArangoClient\n",
    "\n",
    "client = ArangoClient(hosts=connection[\"url\"])\n",
    "\n",
    "db = client.db(\n",
    "    connection[\"dbName\"],\n",
    "    connection[\"username\"],\n",
    "    connection[\"password\"],\n",
    "    verify=True\n",
    ")\n",
    "\n",
    "db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fedd26b9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fedd26b9",
    "outputId": "517f1edb-8236-4c9e-ddb8-fb40d96214e2"
   },
   "outputs": [],
   "source": [
    "# 4: Load sample data\n",
    "# We'll be relying on our Game Of Thrones dataset, representing the parent-child\n",
    "# relationships of certain characters from the GoT universe\n",
    "\n",
    "from arango_datasets import Datasets\n",
    "\n",
    "Datasets(db).load(\"GAME_OF_THRONES\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3de44f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4e3de44f",
    "outputId": "93d60a3c-e091-46f0-fe45-738cb847a805"
   },
   "outputs": [],
   "source": [
    "# 5: Instantiate the ArangoDB-LangChain Graph wrapper\n",
    "\n",
    "from langchain.graphs import ArangoGraph\n",
    "\n",
    "graph = ArangoGraph(db)\n",
    "\n",
    "graph.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mZ679anj_-Er",
   "metadata": {
    "id": "mZ679anj_-Er"
   },
   "outputs": [],
   "source": [
    "# 6: Set your OpenAI API Key\n",
    "# https://help.openai.com/en/articles/4936850-where-do-i-find-my-secret-api-key\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "V1PMxRubKxmK",
   "metadata": {
    "id": "V1PMxRubKxmK"
   },
   "outputs": [],
   "source": [
    "# 7: Instantiate the OpenAI Chat model\n",
    "# Note that other models can be used as well\n",
    "# Ref: https://github.com/langchain-ai/langchain/tree/master/libs/langchain/langchain/chat_models\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(temperature=0, model_name='gpt-4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7476ce98",
   "metadata": {
    "id": "7476ce98"
   },
   "outputs": [],
   "source": [
    "# 8: Instantiate the LangChain Question-Answering Chain with\n",
    "# our **model** and **graph**\n",
    "\n",
    "from langchain.chains import ArangoGraphQAChain\n",
    "\n",
    "chain = ArangoGraphQAChain.from_llm(model, graph=graph, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "MdTyIwWeL953",
   "metadata": {
    "id": "MdTyIwWeL953"
   },
   "source": [
    "## Prompting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f92bb2",
   "metadata": {},
   "source": [
    "\"Prompting\" is the process of providing a language model with a set of text-based instructions to achieve some arbitrary output. The text can be as simple as a single word, or as complex as a full paragraph. The model is responsible for generating a response based on the content of the prompt.\n",
    "\n",
    "This section will utilize the [ChatOpenAI](https://python.langchain.com/docs/integrations/chat/openai) wrapper under the hood to translate Natural Language into ArangoDB Query Language (AQL) queries. In fact, the `chain` object we've created is responsible for the following steps:\n",
    "1. Translate the Natural Language Prompt into an AQL Query\n",
    "2. Execute the AQL Query against the ArangoDB database to retrieve a JSON Result\n",
    "3. If a query error occurs, go back to step 1 with a modified prompt to include the error message\n",
    "3. Translate the JSON Result to a Natural Language answer\n",
    "\n",
    "Let's take a look at how this works in practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8ee27b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "id": "ef8ee27b",
    "outputId": "47f38cbc-7e6b-404f-8bfe-bbd527797471"
   },
   "outputs": [],
   "source": [
    "chain.invoke(\"Who are the 2 youngest characters?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9CSig1BgA76q",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 288
    },
    "id": "9CSig1BgA76q",
    "outputId": "32d6879f-8814-438d-81c0-3456005fcdc6"
   },
   "outputs": [],
   "source": [
    "chain.invoke(\"How are Bran Stark and Arya Stark related?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9Fzdic_pA_4y",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 250
    },
    "id": "9Fzdic_pA_4y",
    "outputId": "08e430d4-963e-441d-80c1-a3e6e585c6f4"
   },
   "outputs": [],
   "source": [
    "chain.invoke(\"Who are Bran Starkâ€™s grandparents?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zq_oeDpAOXpF",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "id": "zq_oeDpAOXpF",
    "outputId": "0ea89f0b-6a19-4908-e8ba-2b8b6f31a61e"
   },
   "outputs": [],
   "source": [
    "chain.invoke(\"Fetch me the character count for each family\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Qfi_e1_P_tKj",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 410
    },
    "id": "Qfi_e1_P_tKj",
    "outputId": "6a01676d-a692-4df0-8e5f-80b1eca25133"
   },
   "outputs": [],
   "source": [
    "chain.invoke(\"What is the age difference between Rickard Stark and Arya Stark?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pjTLW6ct_71q",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 268
    },
    "id": "pjTLW6ct_71q",
    "outputId": "492fa335-4777-430d-df99-d376f1efd620"
   },
   "outputs": [],
   "source": [
    "chain.invoke(\"Wie alt ist Rickard Stark?\") # (German: \"How old is Rickard Stark?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "-VfkVtt4_9FK",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "id": "-VfkVtt4_9FK",
    "outputId": "b718d045-9f29-4ce8-ed12-caf7bf889422"
   },
   "outputs": [],
   "source": [
    "chain.invoke(\"What is the average age within the Stark family?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89-QJ87m__ol",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 288
    },
    "id": "89-QJ87m__ol",
    "outputId": "b869d5f7-aee9-44db-fcea-cbcbc8888fee"
   },
   "outputs": [],
   "source": [
    "chain.invoke(\"Does Bran Stark have a dead parent?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "MV6ENBJVAB-w",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 377
    },
    "id": "MV6ENBJVAB-w",
    "outputId": "9c47e38f-d428-4f9f-bd7e-e0e7cf3a7651"
   },
   "outputs": [],
   "source": [
    "chain.invoke(\"Who are Catelyn Stark's children?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_2maN0_sAFCO",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "id": "_2maN0_sAFCO",
    "outputId": "1b5b1f62-57fa-4d22-d3eb-14ca5cff1c1f"
   },
   "outputs": [],
   "source": [
    "chain.invoke(\"Add Jon Snow, 31, a male character\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_MHWiAVeM3Cg",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 232
    },
    "id": "_MHWiAVeM3Cg",
    "outputId": "73b4e8df-ede4-465d-8af3-f719baa8d3c8"
   },
   "outputs": [],
   "source": [
    "chain.invoke(\"Create a ChildOf edge from Jon Snow to Ned Stark\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3mU0MyGsM6gX",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 305
    },
    "id": "3mU0MyGsM6gX",
    "outputId": "8f9f281d-d524-459c-c4cc-947d547f2795"
   },
   "outputs": [],
   "source": [
    "chain.invoke(\"Who is related to Ned Stark?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jpK1CTypN0s6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "id": "jpK1CTypN0s6",
    "outputId": "a38af56d-0f05-4bba-d913-c63301d0d8d0"
   },
   "outputs": [],
   "source": [
    "chain.invoke(\"What can you tell me about the characters?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rjJd8BCMN6TE",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 288
    },
    "id": "rjJd8BCMN6TE",
    "outputId": "9aa8448d-a879-43eb-a3b9-3a8c4e78faa0"
   },
   "outputs": [],
   "source": [
    "chain.invoke(\"What is the shortest path from Bran Stark to Rickard Stark?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "h1OgY3LbOZmI",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 288
    },
    "id": "h1OgY3LbOZmI",
    "outputId": "f0ec4dd7-3851-41ef-e767-d4526d714119"
   },
   "outputs": [],
   "source": [
    "chain.invoke(\"What is th family tree of Joffrey Baratheon?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "BOcwm5eIN795",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 288
    },
    "id": "BOcwm5eIN795",
    "outputId": "02f90bfd-310d-491a-8103-673675f8b436"
   },
   "outputs": [],
   "source": [
    "chain.invoke(\"What is the relationship between Bran Stark and Rickard Stark?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vxZYOwH5ORVp",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 288
    },
    "id": "vxZYOwH5ORVp",
    "outputId": "65ff944a-f13d-4e41-9005-8619c1dc02ae"
   },
   "outputs": [],
   "source": [
    "chain.invoke(\"Are Arya Stark and Ned Stark related?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0qYH7IG1OWFm",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 268
    },
    "id": "0qYH7IG1OWFm",
    "outputId": "62cf974f-28da-4dc9-e881-1877c59794bc"
   },
   "outputs": [],
   "source": [
    "chain.invoke(\"Is Ned Stark alive?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "H_k57SLRODIv",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 232
    },
    "id": "H_k57SLRODIv",
    "outputId": "dd457f27-2e49-4e5c-de80-9cc004ecf8c5"
   },
   "outputs": [],
   "source": [
    "chain.invoke(\"Ned Stark has died. Update the data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ghVJEfZuOMcK",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 268
    },
    "id": "ghVJEfZuOMcK",
    "outputId": "8eee9960-01f4-4bb6-cf0b-819b21eaea90"
   },
   "outputs": [],
   "source": [
    "chain.invoke(\"How many characters are alive? How many characters are dead?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "NmR7P693ONPl",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 288
    },
    "id": "NmR7P693ONPl",
    "outputId": "1e59c88e-ab95-40cf-fc95-2dfc1faee66d"
   },
   "outputs": [],
   "source": [
    "chain.invoke(\"Is Arya Stark an orphan?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Ob_3aGauGd7d",
   "metadata": {
    "id": "Ob_3aGauGd7d"
   },
   "source": [
    "## Prompt Modifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a486450e",
   "metadata": {},
   "source": [
    "[Prompt Engineering](https://en.wikipedia.org/wiki/Prompt_engineering) can be defined as process of improving a prompt to achieve a better result from a language model.\n",
    "\n",
    "The `chain` object comes with a set of built-in prompt modifiers that can be used to improve the quality of the results. These modifiers are:\n",
    "- `top_k`: Limit the maximum number of results returned by the AQL Query execution\n",
    "- `max_aql_generation_attempts`: Limit the maximum number of times the AQL Query is generated before giving up (i.e if the query is invalid)\n",
    "- `return_aql_query`: Return the AQL Query as part of the output dictionary (useful for debugging)\n",
    "- `return_aql_result`: Return the AQL Query Result as part of the output dictionary (useful for debugging)\n",
    "- `aql_examples`: A list of AQL Examples for the model to learn from when generating the next AQL Query. This is a powerful tool for teaching the model how to generate AQL Queries for your specific dataset.\n",
    "\n",
    "Let's start by looking at the `aql_examples` modifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Q7zxc0kBPhpg",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 250
    },
    "id": "Q7zxc0kBPhpg",
    "outputId": "d3568780-931d-43d5-8b10-5a71b306e1ee"
   },
   "outputs": [],
   "source": [
    "# Notice how the following prompt returns nothing;\n",
    "chain.invoke(\"Who are the grandchildren of Rickard Stark?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zoxZwQh5Pj4J",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 305
    },
    "id": "zoxZwQh5Pj4J",
    "outputId": "4cdf5564-5dee-4e1b-e0f1-c3e3f07a8ca9"
   },
   "outputs": [],
   "source": [
    "# This is because the wrong AQL Traversal direction is used! LLMs can hallucinate.. \n",
    "# A simple reminder to use INBOUND (instead of OUTBOUND) returns the correct result;\n",
    "chain.invoke(\"Who are the grandchildren of Rickard Stark? Remember to use INBOUND\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7WHxkGPPPk8-",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 270
    },
    "id": "7WHxkGPPPk8-",
    "outputId": "d927feea-73c1-4f50-db6c-d0b9afbfe8d0"
   },
   "outputs": [],
   "source": [
    "# We can solidify this pattern by making using of **chain.aql_examples**\n",
    "\n",
    "# The AQL Examples modifier instructs the LLM to adapt its AQL-completion style\n",
    "# to the userâ€™s examples. These examples are passed to the AQL Generation Prompt\n",
    "# Template to promote few-shot-learning.\n",
    "\n",
    "chain.aql_examples = \"\"\"\n",
    "# Who are the grandchildren of Rickard Stark?\n",
    "WITH Characters, ChildOf\n",
    "FOR v, e IN 2..2 INBOUND 'Characters/RickardStark' ChildOf\n",
    "  RETURN v\n",
    "\n",
    "# Is Ned Stark alive?\n",
    "RETURN DOCUMENT('Characters/NedStark').alive\n",
    "\n",
    "...\n",
    "\"\"\"\n",
    "\n",
    "# Note how we are no longer specifying the use of INBOUND\n",
    "chain.invoke(\"Who is the grandchildren of Tywin Lannister?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1B9h3PvzJ41T",
   "metadata": {
    "id": "1B9h3PvzJ41T"
   },
   "outputs": [],
   "source": [
    "# Other modifiers include:\n",
    "\n",
    "# Specify the maximum number of AQL Query Results to return\n",
    "chain.top_k = 5\n",
    "\n",
    "# Specify the maximum amount of AQL Generation attempts that should be made\n",
    "# before returning an error\n",
    "chain.max_aql_generation_attempts = 5\n",
    "\n",
    "# Specify whether or not to return the AQL Query in the output dictionary\n",
    "# Use `chain(\"...\")` instead of `chain.invoke(\"...\")` to see this change\n",
    "chain.return_aql_query = True\n",
    "\n",
    "# Specify whether or not to return the AQL JSON Result in the output dictionary\n",
    "# Use `chain(\"...\")` instead of `chain.invoke(\"...\")` to see this change\n",
    "chain.return_aql_result = True"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "WejTADc2L72f",
    "MdTyIwWeL953",
    "Ob_3aGauGd7d",
    "7waPnt2pLx16"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
